{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informações importantes\n",
    "\n",
    "Este notebook foi executado na plataforma Google Colaboratory, pois não consegui executar em minha máquina, exigia muito processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JO_ES6U8xK3G",
    "outputId": "5e49001d-5df4-4205-9cec-3232db6ec8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 1.x selected.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-DI91M1xit_"
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnOp65WexVkq"
   },
   "outputs": [],
   "source": [
    "def create_binary_list_from_int(number: int) -> List[int]:\n",
    "    if number < 0 or type(number) is not int:\n",
    "        raise ValueError(\"Only Positive integers are allowed\")\n",
    "\n",
    "    return [int(x) for x in list(bin(number))[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3njnC00lxY4K"
   },
   "outputs": [],
   "source": [
    "def generate_even_data(\n",
    "    max_int: int, batch_size: int = 16\n",
    ") -> Tuple[List[int], List[List[int]]]:\n",
    "    \n",
    "    max_length = int(math.log(max_int, 2))\n",
    "\n",
    "    sampled_integers = np.random.randint(0, int(max_int / 2), batch_size)\n",
    "\n",
    "    labels = [1] * batch_size\n",
    "\n",
    "    data = [create_binary_list_from_int(int(x * 2)) for x in sampled_integers]\n",
    "    data = [([0] * (max_length - len(x))) + x for x in data]\n",
    "\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ww1g7nPNxpyY"
   },
   "outputs": [],
   "source": [
    "def convert_float_matrix_to_int_list(\n",
    "    float_matrix: np.array, threshold: float = 0.5\n",
    ") -> List[int]:\n",
    "    return [\n",
    "        int(\"\".join([str(int(y)) for y in x]), 2) for x in float_matrix >= threshold\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0sCJF1fKxsDd"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZ17-FrBx36S"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense_layer = nn.Linear(int(input_length), int(input_length))\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fnvxOJGx777"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_length: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense = nn.Linear(int(input_length), 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.dense(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UZhArzY7x_IE"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yq417DKtyGJT"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    max_int: int = 128,\n",
    "    batch_size: int = 16,\n",
    "    training_steps: int = 500,\n",
    "    learning_rate: float = 0.001,\n",
    "    print_output_every_n_steps: int = 10,\n",
    ") -> Tuple[nn.Module]:\n",
    "    \n",
    "    input_length = int(math.log(max_int, 2))\n",
    "\n",
    "    \n",
    "    generator = Generator(input_length)\n",
    "    discriminator = Discriminator(input_length)\n",
    "\n",
    "    \n",
    "    generator_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "    discriminator_optimizer = torch.optim.Adam(\n",
    "        discriminator.parameters(), lr=learning_rate\n",
    "    )\n",
    "\n",
    "    \n",
    "    loss = nn.BCELoss()\n",
    "\n",
    "    for i in range(training_steps):\n",
    "        generator_optimizer.zero_grad()\n",
    "\n",
    "        noise = torch.randint(0, 2, size=(batch_size, input_length)).float()\n",
    "        generated_data = generator(noise)\n",
    "\n",
    "        true_labels, true_data = generate_even_data(max_int, batch_size=batch_size)\n",
    "        true_labels = torch.tensor(true_labels).float()\n",
    "        true_data = torch.tensor(true_data).float()\n",
    "\n",
    "        generator_discriminator_out = discriminator(generated_data)\n",
    "        generator_loss = loss(generator_discriminator_out, true_labels)\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        true_discriminator_out = discriminator(true_data)\n",
    "        true_discriminator_loss = loss(true_discriminator_out, true_labels)\n",
    "\n",
    "        generator_discriminator_out = discriminator(generated_data.detach())\n",
    "        generator_discriminator_loss = loss(\n",
    "            generator_discriminator_out, torch.zeros(batch_size)\n",
    "        )\n",
    "        discriminator_loss = (\n",
    "            true_discriminator_loss + generator_discriminator_loss\n",
    "        ) / 2\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        if i % print_output_every_n_steps == 0:\n",
    "            print(convert_float_matrix_to_int_list(generated_data))\n",
    "\n",
    "    return generator, discriminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mN5ewuLNyUQX",
    "outputId": "e0c9fd37-d8f6-4630-bd96-0bd95fab99de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38, 103, 38, 44, 39, 7, 38, 39, 70, 34, 39, 46, 100, 38, 76, 38]\n",
      "[37, 3, 44, 7, 7, 44, 103, 3, 7, 44, 39, 74, 39, 7, 3, 6]\n",
      "[108, 39, 42, 45, 12, 14, 108, 35, 14, 34, 7, 39, 39, 38, 10, 79]\n",
      "[44, 39, 14, 108, 6, 99, 103, 39, 6, 15, 43, 44, 101, 36, 45, 38]\n",
      "[39, 39, 74, 39, 3, 7, 14, 44, 47, 39, 7, 39, 108, 103, 108, 103]\n",
      "[39, 46, 39, 45, 39, 105, 7, 103, 39, 72, 12, 103, 39, 36, 39, 39]\n",
      "[43, 39, 43, 39, 111, 72, 103, 103, 2, 75, 40, 43, 109, 47, 71, 40]\n",
      "[47, 109, 34, 47, 45, 43, 103, 107, 75, 11, 109, 43, 39, 35, 3, 109]\n",
      "[109, 107, 45, 109, 105, 103, 38, 101, 44, 99, 40, 45, 101, 39, 39, 43]\n",
      "[105, 109, 109, 41, 34, 39, 109, 35, 99, 103, 99, 40, 47, 35, 109, 41]\n",
      "[41, 109, 43, 109, 107, 103, 103, 105, 105, 45, 47, 43, 109, 43, 105, 105]\n",
      "[45, 105, 109, 103, 107, 39, 99, 39, 101, 99, 99, 41, 97, 43, 109, 109]\n",
      "[105, 109, 105, 103, 105, 47, 109, 35, 103, 105, 103, 35, 40, 43, 109, 45]\n",
      "[109, 41, 109, 105, 109, 105, 45, 105, 109, 43, 105, 103, 45, 40, 103, 35]\n",
      "[43, 75, 109, 43, 103, 109, 43, 105, 105, 105, 35, 105, 39, 41, 109, 105]\n",
      "[105, 45, 43, 105, 121, 40, 41, 105, 109, 103, 40, 103, 43, 109, 99, 105]\n",
      "[109, 105, 105, 109, 109, 105, 109, 41, 109, 99, 45, 107, 41, 105, 99, 105]\n",
      "[105, 41, 109, 109, 105, 105, 105, 109, 107, 105, 107, 105, 105, 105, 40, 99]\n",
      "[105, 105, 99, 105, 105, 99, 107, 109, 43, 105, 107, 105, 109, 43, 105, 105]\n",
      "[121, 105, 121, 35, 109, 121, 109, 105, 105, 105, 105, 107, 41, 121, 109, 107]\n",
      "[105, 121, 105, 105, 105, 121, 121, 105, 105, 121, 75, 105, 105, 105, 109, 43]\n",
      "[105, 121, 121, 99, 107, 109, 121, 105, 41, 99, 109, 121, 105, 105, 105, 105]\n",
      "[105, 107, 105, 121, 99, 105, 105, 121, 105, 99, 121, 41, 121, 105, 105, 107]\n",
      "[121, 109, 107, 121, 41, 121, 121, 75, 105, 121, 121, 121, 107, 105, 105, 105]\n",
      "[121, 105, 41, 107, 107, 121, 107, 121, 107, 107, 121, 43, 121, 107, 107, 107]\n",
      "[121, 121, 123, 121, 123, 123, 121, 121, 121, 121, 121, 107, 121, 107, 121, 107]\n",
      "[121, 121, 121, 105, 41, 121, 75, 121, 105, 123, 115, 107, 115, 107, 121, 121]\n",
      "[107, 121, 121, 105, 123, 121, 121, 43, 105, 123, 121, 121, 121, 107, 121, 107]\n",
      "[121, 123, 121, 91, 105, 123, 121, 91, 123, 107, 121, 105, 91, 121, 123, 109]\n",
      "[115, 121, 75, 123, 91, 89, 121, 115, 89, 121, 91, 91, 75, 123, 91, 121]\n",
      "[121, 123, 91, 121, 91, 91, 121, 75, 121, 123, 91, 91, 75, 123, 59, 123]\n",
      "[91, 123, 121, 59, 91, 89, 91, 121, 42, 91, 123, 121, 91, 91, 121, 89]\n",
      "[89, 91, 125, 91, 72, 123, 89, 91, 91, 91, 123, 91, 91, 91, 91, 123]\n",
      "[123, 121, 91, 91, 123, 59, 91, 91, 115, 72, 91, 121, 91, 91, 91, 91]\n",
      "[59, 89, 91, 91, 123, 91, 91, 123, 91, 91, 120, 91, 91, 123, 123, 123]\n",
      "[91, 88, 91, 91, 91, 91, 91, 91, 88, 91, 91, 91, 88, 90, 91, 91]\n",
      "[91, 91, 121, 91, 91, 90, 91, 91, 123, 91, 91, 91, 91, 91, 91, 90]\n",
      "[91, 91, 91, 91, 26, 91, 123, 91, 91, 91, 91, 122, 115, 90, 91, 91]\n",
      "[91, 90, 91, 91, 91, 91, 91, 91, 123, 91, 90, 91, 91, 90, 91, 91]\n",
      "[91, 91, 115, 91, 91, 91, 90, 91, 90, 91, 83, 91, 90, 91, 90, 91]\n",
      "[90, 90, 83, 91, 91, 123, 90, 90, 90, 90, 91, 91, 91, 90, 120, 91]\n",
      "[90, 83, 120, 91, 90, 91, 90, 91, 91, 90, 90, 90, 91, 88, 91, 91]\n",
      "[120, 88, 120, 90, 94, 90, 91, 90, 90, 90, 94, 90, 83, 90, 90, 90]\n",
      "[90, 90, 94, 90, 90, 91, 90, 91, 26, 90, 91, 122, 83, 90, 90, 88]\n",
      "[90, 90, 91, 90, 90, 90, 90, 90, 90, 91, 90, 90, 90, 90, 90, 90]\n",
      "[94, 122, 90, 90, 26, 90, 90, 90, 90, 90, 90, 83, 90, 90, 114, 90]\n",
      "[90, 90, 90, 90, 90, 90, 126, 94, 50, 90, 90, 90, 90, 90, 50, 90]\n",
      "[90, 90, 90, 88, 90, 122, 90, 26, 94, 88, 90, 90, 90, 90, 90, 90]\n",
      "[90, 90, 82, 94, 90, 90, 90, 90, 92, 122, 90, 90, 90, 94, 94, 90]\n",
      "[90, 90, 90, 90, 90, 90, 94, 90, 90, 26, 90, 122, 90, 118, 90, 92]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Generator(\n",
       "   (dense_layer): Linear(in_features=7, out_features=7, bias=True)\n",
       "   (activation): Sigmoid()\n",
       " ), Discriminator(\n",
       "   (dense): Linear(in_features=7, out_features=1, bias=True)\n",
       "   (activation): Sigmoid()\n",
       " ))"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdPqAFlCyWO4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
