{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise da base de dados\n",
    "\n",
    "Para conseguir rodar este notebook em minha máquina, precisei reduzir bastante o tamanho da base de dados, ficando em torno de 1.500 imagens por classe. Pois com a quantidade original, estava estourando o limite de memória. Sem utilizar o pca, como é apresentado no arquivo *knn-sem-pca.ipynb*, consegui utilizar todas as 25.000 imagens, no entanto neste notebook não consegui, precisei reduzir a quantidade. \n",
    "\n",
    "A estrutura de arquivos da base de dados foi um pouco modificada para esta implementação, utilizando como base a base de dados da kaggle disponível neste link: https://www.kaggle.com/c/dogs-vs-cats/data. Esta modificação facilita um pouco mais o processamento das imagens. A estrutura final segue a seguinte ordem:\n",
    "\n",
    "- dogscats\n",
    "  - train\n",
    "     - cats\n",
    "     - dogs\n",
    "  - valid\n",
    "     - cats\n",
    "     - dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./dogscats\"\n",
    "train_dir = dataset_path + \"/train\"\n",
    "val_dir =dataset_path + \"/valid\"\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dogscats/train/dogs/dog.75.jpg\n",
      "./dogscats/train/dogs/dog.757.jpg\n",
      "./dogscats/train/dogs/dog.761.jpg\n",
      "./dogscats/train/dogs/dog.762.jpg\n",
      "./dogscats/train/dogs/dog.763.jpg\n",
      "./dogscats/train/dogs/dog.764.jpg\n",
      "./dogscats/train/dogs/dog.765.jpg\n",
      "./dogscats/train/dogs/dog.767.jpg\n",
      "./dogscats/train/dogs/dog.781.jpg\n",
      "./dogscats/train/dogs/dog.803.jpg\n",
      "./dogscats/train/dogs/dog.81.jpg\n",
      "./dogscats/train/dogs/dog.810.jpg\n",
      "./dogscats/train/dogs/dog.811.jpg\n",
      "./dogscats/train/dogs/dog.812.jpg\n",
      "./dogscats/train/dogs/dog.813.jpg\n",
      "./dogscats/train/dogs/dog.814.jpg\n",
      "./dogscats/train/dogs/dog.815.jpg\n",
      "./dogscats/train/dogs/dog.816.jpg\n",
      "./dogscats/train/dogs/dog.817.jpg\n",
      "./dogscats/train/dogs/dog.818.jpg\n",
      "./dogscats/train/dogs/dog.819.jpg\n",
      "./dogscats/train/dogs/dog.82.jpg\n",
      "./dogscats/train/dogs/dog.820.jpg\n",
      "./dogscats/train/dogs/dog.821.jpg\n",
      "./dogscats/train/dogs/dog.822.jpg\n",
      "./dogscats/train/dogs/dog.823.jpg\n",
      "./dogscats/train/dogs/dog.825.jpg\n",
      "./dogscats/train/dogs/dog.826.jpg\n",
      "./dogscats/train/dogs/dog.827.jpg\n",
      "./dogscats/train/dogs/dog.828.jpg\n",
      "./dogscats/train/dogs/dog.829.jpg\n",
      "./dogscats/train/dogs/dog.83.jpg\n",
      "./dogscats/train/dogs/dog.830.jpg\n",
      "./dogscats/train/dogs/dog.831.jpg\n",
      "./dogscats/train/dogs/dog.832.jpg\n",
      "./dogscats/train/dogs/dog.833.jpg\n",
      "./dogscats/train/dogs/dog.834.jpg\n",
      "./dogscats/train/dogs/dog.835.jpg\n",
      "./dogscats/train/dogs/dog.836.jpg\n",
      "./dogscats/train/dogs/dog.837.jpg\n",
      "./dogscats/train/dogs/dog.838.jpg\n",
      "./dogscats/train/dogs/dog.839.jpg\n",
      "./dogscats/train/dogs/dog.84.jpg\n",
      "./dogscats/train/dogs/dog.840.jpg\n",
      "./dogscats/train/dogs/dog.841.jpg\n",
      "./dogscats/train/dogs/dog.842.jpg\n",
      "./dogscats/train/dogs/dog.843.jpg\n",
      "./dogscats/train/dogs/dog.844.jpg\n",
      "./dogscats/train/dogs/dog.845.jpg\n",
      "./dogscats/train/dogs/dog.846.jpg\n",
      "./dogscats/train/dogs/dog.847.jpg\n",
      "./dogscats/train/dogs/dog.848.jpg\n",
      "./dogscats/train/dogs/dog.849.jpg\n",
      "./dogscats/train/dogs/dog.85.jpg\n",
      "./dogscats/train/dogs/dog.850.jpg\n",
      "./dogscats/train/dogs/dog.851.jpg\n",
      "./dogscats/train/dogs/dog.852.jpg\n",
      "./dogscats/train/dogs/dog.853.jpg\n",
      "./dogscats/train/dogs/dog.854.jpg\n",
      "./dogscats/train/dogs/dog.856.jpg\n",
      "./dogscats/train/dogs/dog.857.jpg\n",
      "./dogscats/train/dogs/dog.858.jpg\n",
      "./dogscats/train/dogs/dog.859.jpg\n",
      "./dogscats/train/dogs/dog.86.jpg\n",
      "./dogscats/train/dogs/dog.860.jpg\n",
      "./dogscats/train/dogs/dog.861.jpg\n",
      "./dogscats/train/dogs/dog.862.jpg\n",
      "./dogscats/train/dogs/dog.863.jpg\n",
      "./dogscats/train/dogs/dog.864.jpg\n",
      "./dogscats/train/dogs/dog.865.jpg\n",
      "./dogscats/train/dogs/dog.866.jpg\n",
      "./dogscats/train/dogs/dog.867.jpg\n",
      "./dogscats/train/dogs/dog.868.jpg\n",
      "./dogscats/train/dogs/dog.869.jpg\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "directory = os.listdir(train_dir + '/dogs')\n",
    "train_dogs = []\n",
    "train_dogs_labels = []\n",
    "for img in directory:\n",
    "    try:#Tive que fazer isso porque algumas imagens corromperam\n",
    "        y = cv2.imread(train_dir + '/dogs/' + img)\n",
    "        x = cv2.resize(y, (size, size))\n",
    "        x = np.array(x)\n",
    "        x = x.flatten()\n",
    "        train_dogs.append(x)\n",
    "        train_dogs_labels.append(1)\n",
    "    except:\n",
    "        print(train_dir + '/dogs/' + img)\n",
    "    \n",
    "train_dogs = np.array(train_dogs)\n",
    "train_dogs_labels = np.array(train_dogs_labels)\n",
    "\n",
    "\n",
    "directory = os.listdir(train_dir + '/cats')\n",
    "train_cats = []\n",
    "train_cats_labels = []\n",
    "for img in directory:\n",
    "    try:\n",
    "        train_cats.append(cv2.resize(cv2.imread(train_dir + '/cats/' + img), (size, size)).reshape(-1))\n",
    "        train_cats_labels.append(0)\n",
    "    except:\n",
    "        print(train_dir + '/cats/' + img)\n",
    "\n",
    "train_cats = np.array(train_cats)\n",
    "train_cats_labels = np.array(train_cats_labels)\n",
    "  \n",
    "# validation set\n",
    "  \n",
    "directory = os.listdir(val_dir + '/dogs')\n",
    "val_dogs = []\n",
    "val_dogs_labels = []\n",
    "for img in directory:\n",
    "    try:\n",
    "        val_dogs.append(cv2.resize(cv2.imread(val_dir + '/dogs/' + img), (size, size)).reshape(-1))\n",
    "        val_dogs_labels.append(1)\n",
    "    except:\n",
    "        print(val_dir + '/dogs/' + img)\n",
    "    \n",
    "val_dogs = np.array(val_dogs)\n",
    "val_dogs_labels = np.array(val_dogs_labels)\n",
    "  \n",
    "directory = os.listdir(val_dir + '/cats')\n",
    "val_cats = []\n",
    "val_cats_labels = []\n",
    "for img in directory:\n",
    "    try:\n",
    "        val_cats.append(cv2.resize(cv2.imread(val_dir + '/cats/' + img), (size, size)).reshape(-1))\n",
    "        val_cats_labels.append(0)\n",
    "    except:\n",
    "        print(val_dir + '/cats/' + img)\n",
    "\n",
    "val_cats = np.array(val_cats)\n",
    "val_cats_labels = np.array(val_cats_labels)\n",
    "\n",
    "x_train = np.concatenate((train_dogs, train_cats))\n",
    "y_train = np.concatenate((train_dogs_labels, train_cats_labels))\n",
    "  \n",
    "x_test = np.concatenate((val_dogs, val_cats))\n",
    "y_test = np.concatenate((val_dogs_labels, val_cats_labels))\n",
    "\n",
    "x_train, y_train = shuffle(x_train, y_train, random_state=123)\n",
    "x_test, y_test = shuffle(x_test, y_test, random_state=123)\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "  \n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(x_train)\n",
    "\n",
    "x_train = pca.transform(x_train)\n",
    "x_test = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(x_train, y_train)\n",
    "score_knn = knn.score(x_test, y_test)\n",
    "print(\"accuracy: {:.2f}%\".format(score_knn * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado\n",
    "\n",
    "Claramente a redução da base de dados afetou completamente a acurácia, principalmente se levarmos em consideração os resultados obtidos com as 25.000 imagens no arquivo *knn-sem-pca.ipynb*, onde o knn é utilizado, porém sem a redução de dimensionalidade e obtém acurácia de 100% de acerto. Portanto, atribuo a baixa acurácia ao número menor de exemplos na base de dados. Caso o resultado da implementação vigente neste arquivo utilizasse as 25.000 imagens e ainda assim obtivesse uma acurácia com discrepância inferior muito alta, isso poderia significar que o pca não conseguiu extrair as caracteristicas mais importantes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
